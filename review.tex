\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{pgfplots}

\title{CS251 Midterm 1 - Fall 2022}
\author{schari}
\date{September 2022}

\begin{document}

\maketitle

\section{Summations and Logarithm Rules}
\begin{itemize}
    \item Summations
        \begin{itemize}
            \item Given $c$ is a constant, $\sum_{i = m}^{n} c = c(n - m + 1)$
            \item $\sum_{i = 1}^{n} i = \frac{1}{2}n(n + 1)$
            \item $\sum_{i = 1}^{n} i^2 = \frac{1}{6}n(n + 1)(2n + 1)$
            \item Given a function $f(i)$, $\sum_{i = m}^{n} f(i) = \sum_{i = 1}^{n} f(i) - \sum_{i = 1}^{m - 1} f(i)$
        \end{itemize}
    \item Log Rules
        \begin{itemize}
            \item In CS 251, if you are just given a $\log(n)$ without a base, they probably mean $\log_2(n)$
            \item $\log(ab) = \log(a) + \log(b)$
            \item $\log(\frac{a}{b}) = \log(a) - \log(b)$
            \item Given 2 numbers $a$ and $b$, $\log_a(n) = \frac{\log_b(n)}{\log_b(a)}$
            \item $\log(n^a) = a \log(n)$
            \item $a^{\log_a(n)} = n$
            \item $a^{b \log_a(n)} = n^b$
        \end{itemize}
\end{itemize}

\section{Experimental Analysis}

\begin{itemize}
    \item Limitations
        \begin{itemize}
        	% Make these more concrete phrases instead of from the slides
            \item Different machines can vary the run time 
            \item other processes/noise
            \item May not be precise all the time 
        \end{itemize}
    \item These limitations are all put together to form constants $c$, which are seen in just about any runtime cost. In the power law, they are lumped together into a proportionality constant $a$.
    \item The power law is the law that $T(n)$ approximately follows the equation $T(n) = a * n^b$. The coefficient $a$ will be based on the hardware, which you cannot control. However, the value of $b$
	\item Given a table that contains data for $n$ and the associated $T(n)$'s, we can check if the data  follows the power law.
	\item Firstly, you can check if the values follow the power law by identifying the ratios between the rows of $T(n)$ and $n$. If the ratio between the rows of $n$ are consistent, then the ratios between the rows of $T(n)$ should also be consistent (though it can be a different ratio and be okay).
		\begin{itemize}
			\item If the ratios between rows of $n$ are not consistent, that doesn't mean it doesn't follow the power law, only that its harder to check. Check the value of $\log_{r_n} (r_{T(n)})$ where $r_n$ is the ratio between two rows of $n$ and $r_{T(n)}$ is the ratio between rows of $T(n)$ (the same rows). For any two rows, this value should be essentially the same for it to follow the power law.
		\end{itemize}
	\item
		Another way of identifying if the values follow the power law is to create a log-log plot. Plot the values of $\log n$ and $\log T(n)$ on a plot and determine if they approximately make a straight line. If they do, they follow the power law.
		\begin{tikzpicture}[domain=0:3]
		\begin{axis}[xlabel={$\log n$}, ylabel={$\log T(n)$}]
		\addplot[scatter, scatter src=\thisrow{class},
			  error bars/.cd, y dir=both, x dir=both, y explicit, x explicit, error bar style={color=mapped color}]
			  table[x=x,y=y] {
			% The data here is absolutely garbage lol. Not at all from reality.
			x       y        class
			0.98521 1        0
			0.49238 0.5      0
			1.09346 1.111111 0
			1.23021 1.25     0
			1.40567 1.428571 0
			1.63971 1.666667 0
			1.96753 2        0
		};
		\end{axis}
		\end{tikzpicture}
	\item
		Once it is identified that data follows the power law, a prediction can be made. If the next value of $n$ given has the same ratio to a previous value, you can use the ratio of $T(n)$ to determine the predicted value of $T(n)$ very easily. 
		\begin{itemize}
			\item Given $T(8) = 16$ and $T(16) = 48$ and that $T(n)$ follows the power law, you can determine $T(64) = T(16 * 2^2) \approx T(16) * 3^2 = 48 * 9 = 432$ (The 2 and 3 are determined from the ratios, $16/8 = 2$ and $48/16$ = 3.)
		\end{itemize}
	\item
		You could be asked for the value of $b$ in $T(n) = a * n^b$. You can determine this via 
		\begin{enumerate}
			\item Determining the slope of the log-log plot. That value is $b$. 
			\item Take the logarithm of the ratio between rows of $T(n)$ with the base of the ratio of the rows of $n$. $b = \log_{r_n} (r_{T(n)})$.
			\begin{itemize}
				\item For the given example of $T(8) = 16$ and $T(16) = 48$, $r_n = 16 / 8 = 2$ and $r_{T(n)} = 48 / 16 = 3$. Therefore, $b = \log_2 3$.
			\end{itemize}
		\end{enumerate}

\end{itemize}

\section{Recursive Functions}
\begin{itemize}
    \item Functions that call themselves in order to solve simpler problems
    \item Recursive functions don't call themselves infinitely; eventually stop when they reach a base case
    \item 
\end{itemize}

\section{Runtime Analysis}
\begin{itemize}
    \item Represents the efficiency of an algorithm
    	\begin{itemize}
    		\item Usually represents the cost of an algorithm for a specific value of n. 
    		\item However, can be amortized if the cost is distributed over an interval of values of n. (Equation is $\sum_{k=a}^{b} T(k) / (b-a+1)$)
    	\end{itemize}
    \item Three types of asymptotic runtime analysis: $O(n)$, $\Omega(n)$, and $\Theta(n)$
    \item $O(n)$
        \begin{itemize}
            \item The asymptotic upper bound
            \item Definition: Given functions $f(n)$ and $g(n)$, then $f(n) \in O(g(n))$ if there exists constants $c$ and $n_0$ where $0 \leq f(n) \leq cg(n)$ for all $n \geq n_0$
            \item In other words, $f(n) \in O(g(n))$ if $f(n)$ doesn't grow faster than $g(n)$.
            \item Growth order:
                \begin{itemize}
                    \item $O(1) < O(\log(n)) < O(n) < O(n \log(n)) < O(n^2) < O(n^3) < O(2^n) < O(n!)$
                \end{itemize}
            \item Going from the definition above, multiple functions can be big-$O$ of another function.
                \begin{itemize}
                    \item Ex: $n \in O(n)$, and $n \in O(n^2)$
                \end{itemize}
            \item Generally, if they're asking for big-$O$ of a function, you want to give the tightest bound of the function.
            \item When giving the $O(n)$ of a function, you take the fastest-growing term and remove the constants from it
                \begin{itemize}
                    \item Ex: $4n^2 + 2n\log(n) + 3n + 123456 \in O(n^2)$
                \end{itemize}
        \end{itemize}
    \item $\Omega(n)$
        \begin{itemize}
            \item Asymptotic lower bound
            \item Definition: Given functions $f(n)$ and $g(n)$, then $f(n) \in \Omega(g(n))$ if there exists constants $c$ and $n_0$ where $0 \leq cg(n) \leq f(n)$ for all $n \geq n_0$
            \item In other words, $f(n) \in \Omega(g(n))$ if $f(n)$ doesn't grow slower than $g(n)$.
            \item Like how multiple functions can be $O(n)$ of a function, multiple functions can also be $\Omega(n)$ of a function
                \begin{itemize}
                    \item Ex: $n \in \Omega(n)$, and $n \in \Omega(\log(n))$
                \end{itemize}
            \item Again, generally you should give the tightest bound
            \item Process for getting big-$\Omega$ of a function is same as getting big-$O$
        \end{itemize}
    \item $\Theta(n)$
        \begin{itemize}
            \item Asymptotic tightest bound of a function
            \item $f(n) \in \Theta(g(n))$ if $f(n)$ doesn't grow faster or slower than $g(n)$
        \end{itemize}
    \item Asymptotic Growth Properties
        \begin{itemize}
            \item If $f(n) \in O(g(n))$ and $f(n) \in \Omega(g(n))$, then $f(n) \in \Omega(g(n))$ and vice versa
            \item If $f(n) \in O(g(n))$ and $g(n) \in O(h(n))$, then $f(n) \in O(h(n))$
            \item If $f(n) \in \Omega(g(n))$ and $g(n) \in \Omega(h(n))$, then $f(n) \in \Omega(h(n))$
            \item If $f(n) \in \Theta(g(n))$ and $g(n) \in \Theta(h(n))$, then $f(n) \in \Theta(h(n))$
            \item If $f(n) \in O(h(n))$ and $g(n) \in O(h(n))$, then $f(n) + g(n) \in O(h(n))$
            \item If $f(n) \in \Theta(g(n))$, then $f(n) + g(n) \in \Theta(g(n))$
            \item If $f(n) \in O(g(n))$, then $g(n) \in \Omega(f(n))$
        \end{itemize}
\end{itemize}


\section{Algorithm Analysis}
\begin{itemize}
    \item Given an algorithm, we need to find the runtime cost of it.
    \item The runtime cost is based on what is specifically deemed worthy of noting. This can be the following:
	    \begin{itemize}
            \item The number of iterations.
                \begin{itemize}
                    \item for$(i = 0; i < n; i++) // $Do something
                \end{itemize}
            \item The value of a variable
                \begin{itemize}
                    \item 
                    $total = 0;$
                    
                    for$(i = 0; i < n; i++)$ $total += i$
                \end{itemize}
            \item The number of times a function is ran.
                \begin{itemize}
                    \item for$(i = 0; i < n; i++) f(i)$ where $f(i)$ has a undefined cost correlating to the arguments.
                \end{itemize}
            \item The summed cost of function calls based on the arguments of the function.
                \begin{itemize}
                    \item for$(i = 0; i < n; i++) f(i)$ where $f(i)$ has a defined cost (e.g. $f(i) = i$ or $f(i) = \log i$).
                \end{itemize}
		\end{itemize}
	\item Some rules that you can follow are the following:
    	\begin{itemize}
    		\item
				Loops and recursion generally turn into sigma notation.
			\item
				If there is an "if" statement or other condition, it is usually better to seperate it into seperate parts or entire equations, instead of trying to keep it in the same parts. This includes things like the base case of a recursive function, if the base case counts as an iteration!
			\item
				If the loop is going backwards, you can turn it around if it makes it easier. (e.g. you can turn subtraction into addition and swap upper and lower bounds, or division to multiplication), Just be careful its still the same iteration values!
			\item
				If the comparison "$< f(n)$" is used, you probably want to use "ceil(f(n)) - 1" ($\lceil f(n) \rceil - 1$) as the upper bound. If its "$<= f(n)$", you probably want "floor(f(n))" ($\lfloor f(n) \rfloor$)
			\item
				However, if looking at an asymptotic cost ($O(n)$, $\Omega(n)$, $\Theta(n)$), then you probably don't need floor and ceil at all, because they are miniscule compared to the entire sum.
    	\end{itemize}
    \item There are a number of ways of taking an algorithm and determining the cost.
    	\begin{itemize}
    		\item
    			Given a loop where a variable is incremented by 1 between each iteration, a simple sigma notation can be used.
    			
    			for$(i = 0; i < n; i++) f(i) \Rightarrow$
    			$\sum_{i=0}^{n-1} T_f(i)$
    		\item
    			Given a loop where a variable is multiplied by c between each iteration, you can use log, and then replace any value of $i$ with $2^k$.
    			
    			for$(i = 1; i < n; i *= c) f(i) \Rightarrow$
    			$\sum_{k=0}^{\lceil \log_c n \rceil - 1} T_f(2^k)$
    		\item
    			Given a recursive function that takes an input $n$, with base case $a$, and does a $f(n)$ cost operation, and then runs itself with value $n-1$, the summation would be:
    			$\sum_{k=a}^{n} f(k)$
    			
    			Notice that this is exactly the same as a loop. For basic recursive functions, they are basically just loops. Anything else you might want induction.
    		\item
    			This is something we haven't covered, but it is useful in some circumstances.
    			Given a loop where a variable is incremented by k between each iteration, you can stretch or squish the sigma accordingly.
    			
    			for$(i = a; i < n; i += k) f(i) \Rightarrow$
    			$\sum_{i=0}^{\lceil(n-a)/k \rceil - 1} T_f(ki + a)$
    	\end{itemize}
\end{itemize}


\section{Arrays and LinkedLists}

\section{Stacks}
\begin{itemize}
    \item Data structure to store and remove data
    \item Last data pushed into the stack would be the first data popped off (LIFO)
        \begin{itemize}
            \item Think of it like a stack of plates; the last plate placed on top is the first plate taken from the stack
        \end{itemize}
    \item Standard methods for stacks:
        \begin{itemize}
            \item \verb|push()| - Add an element to the top of the stack
            \item \verb|pop()| - Remove the element from the top of the stack
            \item \verb|isEmpty()| - Whether or not there are elements on the stock
            \item \verb|size()| - Number of elements on the stack
            \item \verb|peek()| - View the element at the top of the stack without removing it
        \end{itemize}
    \item Implementation using Arrays vs LinkedLists
        \begin{itemize}
            \item Arrays: Lower memory overhead; unable to resize to accomodate more elements
            \item LinkedLists: Pointers require more memory; can expand to increase number of elements in the stack
        \end{itemize}
\end{itemize}

\section{Queues}
\begin{itemize}
    \item Data structure to store and remove data
    \item First data enqueued would be the first data dequeued (FIFO)
        \begin{itemize}
            \item Think of it as a queue of people; first person to enter is also the first person who gets served
        \end{itemize}
    \item Standard methods for queues:
        \begin{itemize}
            \item \verb|enqueue()| - Add an element to the end of the queue
            \item \verb|dequeue()| - Remove the element from the front of the queue
            \item \verb|isEmpty()| - Whether or not there are elements in the queue
            \item \verb|size()| - Number of elements in the queue
            \item \verb|peek()| - View the element at the front of the queue without removing it
        \end{itemize}
    \item Implementation using Arrays vs LinkedLists
        \begin{itemize}
            \item Arrays: In addition to lower memory overhead, a queue implementation will loop from the end of array to the front, and will keep track of the index of the front and back of the queue (see slides for example).
            \item LinkedLists: Because LinkedLists are relatively resizable, you don't need to keep track of indices, but you will have to keep track of the front and back of the queue nodes.
        \end{itemize}
\end{itemize}

\section{Trees}

\end{document}

